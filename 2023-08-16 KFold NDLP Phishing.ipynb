{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/akritidu/Multi-label-Classification-in-the-Home-Improvement/blob/main/LSTM_Bi_LSTM_GRU_Bi_GRU.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Uploading and Cleaning "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "jiThwmlfRC_w"
   },
   "outputs": [],
   "source": [
    "\n",
    "from numpy import array\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Activation, Dropout, Dense\n",
    "from tensorflow.keras.layers import Flatten, LSTM, GRU, Bidirectional, GlobalAveragePooling1D\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D, SpatialDropout1D, GlobalMaxPool1D, BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Embedding\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.layers import Input\n",
    "from tensorflow.keras.layers import Concatenate\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, SimpleRNN, Embedding, Dropout, SpatialDropout1D, Activation, Conv1D,GRU\n",
    "from tensorflow.keras.layers import Conv1D, Bidirectional, GlobalMaxPool1D, MaxPooling1D, BatchNormalization, Add, Flatten\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D, GlobalAveragePooling1D, concatenate, SpatialDropout1D\n",
    "\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2.to_csv('2023-08-08-clean_file.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('2023-08-08-clean_file.csv') #actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_df = df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>contexts</th>\n",
       "      <th>ham</th>\n",
       "      <th>phishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>google window google bypjtqaxxnab getei functi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>function envflush function window require requ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>timing timing timing tick function label time ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>yahoo deutschland roundtrip rttop number date ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>html overflow-y auto body font arial text-alig...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>wikipedia unicode-bidi embed white-space nowra...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dtfirstbyte date meta http-equiv refresh conte...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>blogger erstellen kostenloses blog html body t...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>twitter document domain twitter copy twttr app...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>body margin pad font-size line-height font-fam...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>date image image pkpdm atvpdkikx uedata gatewa...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>window window global webtrack object timing in...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>google window google frjlt dopztiz getei funct...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>deutschland hotmail skype messenger sowie nach...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>window config appid monitor date body font-fam...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>yahoo japan body form fieldset input button bl...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>function padurl location href indexof return i...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>wordpress free blog -page loggedin width displ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>google window google lljlt ej-ga getei functio...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>google window google hyhs-gay sibda getei func...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>pagehasrtmplacements true ff-left display none...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>google window google rbjlt iznpgg-abd getei fu...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>document documentelement document compatmode c...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>google window google vljlt fjmxsoeoz getei fun...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>cdata date cdata date de-de false eventid serp...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>google window google yrjlt id-wa getei functio...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>config lang severtime token product miniblog p...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>error found margin pad html code font arial sa...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>twitter margin pad border body background colo...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>microsoft corporation software smartphones onl...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9731</th>\n",
       "      <td>payment processing transaction merchant servic...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9732</th>\n",
       "      <td>online christian date christian single christi...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9733</th>\n",
       "      <td>welcome intercontinental bank</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9734</th>\n",
       "      <td>wind runcontent runcontent function tclear def...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9735</th>\n",
       "      <td>maybank online financial service</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9736</th>\n",
       "      <td>contain left background image dian no-repeat l...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9737</th>\n",
       "      <td>welcome metrobankdirect document layer documen...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9738</th>\n",
       "      <td>rune legacy runescape private server table tab...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9739</th>\n",
       "      <td>preleads home home solution testimonial get st...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9740</th>\n",
       "      <td>login access personal detail</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9741</th>\n",
       "      <td>bank islam internet banking function checkurl ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9742</th>\n",
       "      <td>request invalid</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9743</th>\n",
       "      <td>optimum online sign body font-family verdana a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9744</th>\n",
       "      <td>home recentcomments display inline important p...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9745</th>\n",
       "      <td>kijiji sign jsonly display none collapsewithjs...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9746</th>\n",
       "      <td>ueinit document backdetect document backdetect...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9747</th>\n",
       "      <td>small balance home nbsp nbsp nbsp login user n...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9748</th>\n",
       "      <td>wcta welcome parent frame length location repl...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9749</th>\n",
       "      <td>haben passwort vergessen width width width dis...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9750</th>\n",
       "      <td>enom domain name site host email registration ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9751</th>\n",
       "      <td>bossini reporting system nbsp nbsp nbsp login ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9752</th>\n",
       "      <td>national bank page load window onload function...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9753</th>\n",
       "      <td>online document write string fromcharcode scri...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9754</th>\n",
       "      <td>sparkasse produkte service ihrer sparkasse pus...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9755</th>\n",
       "      <td>comprovante situa cadastral registra input pos...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9756</th>\n",
       "      <td>crefisa function abrepopup janela window open ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9757</th>\n",
       "      <td>welcome atbonline business page upgraded produ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9758</th>\n",
       "      <td>window document location href internet browser...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9759</th>\n",
       "      <td>scam alert</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9760</th>\n",
       "      <td>portail banque postale popupwidth popupheight ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9761 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               contexts  ham  phishing\n",
       "0     google window google bypjtqaxxnab getei functi...    1         0\n",
       "1     function envflush function window require requ...    1         0\n",
       "2     timing timing timing tick function label time ...    1         0\n",
       "3     yahoo deutschland roundtrip rttop number date ...    1         0\n",
       "4     html overflow-y auto body font arial text-alig...    1         0\n",
       "5     wikipedia unicode-bidi embed white-space nowra...    1         0\n",
       "6     dtfirstbyte date meta http-equiv refresh conte...    1         0\n",
       "7     blogger erstellen kostenloses blog html body t...    1         0\n",
       "8     twitter document domain twitter copy twttr app...    1         0\n",
       "9     body margin pad font-size line-height font-fam...    1         0\n",
       "10    date image image pkpdm atvpdkikx uedata gatewa...    1         0\n",
       "11    window window global webtrack object timing in...    1         0\n",
       "12    google window google frjlt dopztiz getei funct...    1         0\n",
       "13    deutschland hotmail skype messenger sowie nach...    1         0\n",
       "14    window config appid monitor date body font-fam...    1         0\n",
       "15    yahoo japan body form fieldset input button bl...    1         0\n",
       "16    function padurl location href indexof return i...    1         0\n",
       "17    wordpress free blog -page loggedin width displ...    1         0\n",
       "18    google window google lljlt ej-ga getei functio...    1         0\n",
       "19    google window google hyhs-gay sibda getei func...    1         0\n",
       "20    pagehasrtmplacements true ff-left display none...    1         0\n",
       "21    google window google rbjlt iznpgg-abd getei fu...    1         0\n",
       "22    document documentelement document compatmode c...    1         0\n",
       "23    google window google vljlt fjmxsoeoz getei fun...    1         0\n",
       "24    cdata date cdata date de-de false eventid serp...    1         0\n",
       "25    google window google yrjlt id-wa getei functio...    1         0\n",
       "26    config lang severtime token product miniblog p...    1         0\n",
       "27    error found margin pad html code font arial sa...    1         0\n",
       "28    twitter margin pad border body background colo...    1         0\n",
       "29    microsoft corporation software smartphones onl...    1         0\n",
       "...                                                 ...  ...       ...\n",
       "9731  payment processing transaction merchant servic...    1         0\n",
       "9732  online christian date christian single christi...    1         0\n",
       "9733                      welcome intercontinental bank    1         0\n",
       "9734  wind runcontent runcontent function tclear def...    1         0\n",
       "9735                   maybank online financial service    1         0\n",
       "9736  contain left background image dian no-repeat l...    1         0\n",
       "9737  welcome metrobankdirect document layer documen...    1         0\n",
       "9738  rune legacy runescape private server table tab...    1         0\n",
       "9739  preleads home home solution testimonial get st...    1         0\n",
       "9740                       login access personal detail    1         0\n",
       "9741  bank islam internet banking function checkurl ...    1         0\n",
       "9742                                    request invalid    1         0\n",
       "9743  optimum online sign body font-family verdana a...    1         0\n",
       "9744  home recentcomments display inline important p...    1         0\n",
       "9745  kijiji sign jsonly display none collapsewithjs...    1         0\n",
       "9746  ueinit document backdetect document backdetect...    1         0\n",
       "9747  small balance home nbsp nbsp nbsp login user n...    1         0\n",
       "9748  wcta welcome parent frame length location repl...    1         0\n",
       "9749  haben passwort vergessen width width width dis...    1         0\n",
       "9750  enom domain name site host email registration ...    1         0\n",
       "9751  bossini reporting system nbsp nbsp nbsp login ...    1         0\n",
       "9752  national bank page load window onload function...    1         0\n",
       "9753  online document write string fromcharcode scri...    1         0\n",
       "9754  sparkasse produkte service ihrer sparkasse pus...    1         0\n",
       "9755  comprovante situa cadastral registra input pos...    1         0\n",
       "9756  crefisa function abrepopup janela window open ...    1         0\n",
       "9757  welcome atbonline business page upgraded produ...    1         0\n",
       "9758  window document location href internet browser...    1         0\n",
       "9759                                         scam alert    1         0\n",
       "9760  portail banque postale popupwidth popupheight ...    1         0\n",
       "\n",
       "[9761 rows x 3 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ham</th>\n",
       "      <th>phishing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ham  phishing\n",
       "0    1         0\n",
       "1    1         0\n",
       "2    1         0\n",
       "3    1         0\n",
       "4    1         0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories = df[['ham', 'phishing']]\n",
    "categories.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GhZvp8XY9aaB",
    "outputId": "a1f5b3f0-bd92-4c96-83a6-741594557c0f"
   },
   "outputs": [],
   "source": [
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "\n",
    "#Lemmatize Words\n",
    "\n",
    "def fetch_pos_tag(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        # As default pos in lemmatization is Noun\n",
    "        return wordnet.NOUN\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "#cleaning the data now \n",
    "\n",
    "regex = [\n",
    "    r'<[^>]+>', #HTML tags\n",
    "    r'@(\\w+)', # @-mentions\n",
    "    r\"#(\\w+)\", # hashtags\n",
    "    r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+', # URLs\n",
    "    r'[^0-9a-z #+_\\\\r\\\\n\\\\t]', #BAD SYMBOLS\n",
    "]\n",
    "\n",
    "REPLACE_URLS = re.compile(r'http[s]?://(?:[a-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9a-f][0-9a-f]))+')\n",
    "REPLACE_HASH = re.compile(r'#(\\w+)')\n",
    "REPLACE_AT = re.compile(r'@(\\w+)')\n",
    "REPLACE_HTML_TAGS = re.compile(r'<[^>]+>')\n",
    "REPLACE_DIGITS = re.compile(r'\\d+')\n",
    "#REPLACE_BY = re.compile(r\"[/(){}\\[\\]\\|,;.:?\\-\\'\\\"$]\")\n",
    "REPLACE_BY = re.compile(r\"[^a-z0-9\\-]\")\n",
    "\n",
    "STOPWORDS = set(stopwords.words('english'))\n",
    "\n",
    "#tokens_re = re.compile(r'('+'|'.join(regex)+')', re.VERBOSE | re.IGNORECASE)\n",
    "\n",
    "# sentences = [] #for Word2Vec model\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = REPLACE_HTML_TAGS.sub(' ', text)\n",
    "    text = REPLACE_URLS.sub('', text)\n",
    "    text = REPLACE_HASH.sub('', text)\n",
    "    text = REPLACE_AT.sub('', text)\n",
    "    text = REPLACE_DIGITS.sub(' ', text)\n",
    "    text = REPLACE_BY.sub(' ', text)\n",
    "    \n",
    "    \n",
    "    text = \" \".join(lemmatizer.lemmatize(word.strip(), fetch_pos_tag(pos_tag([word.strip()])[0][1])) for word in text.split() if word not in STOPWORDS and len(word)>3)\n",
    "    \n",
    "    #sentences.append(text.split())\n",
    "    return text\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MoFYZG2J-Wh8"
   },
   "outputs": [],
   "source": [
    "# train_df['contexts'] = train_df['contexts'].apply(clean_text) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for single output layer\n",
    "X  = df['contexts'] \n",
    "y = categories.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prueba 2 para evaluar \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# # comento el 16 de goto de 2023\n",
    "# Tokenizar los datos de texto\n",
    "tokenizer = Tokenizer(num_words=3000)\n",
    "tokenizer.fit_on_texts(X)\n",
    "X = tokenizer.texts_to_sequences(X)\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "# Ajustar las secuencias a una longitud fija\n",
    "maxlen = 200\n",
    "X = pad_sequences(X, padding='post', maxlen=maxlen)\n",
    "# # cierro comento el 16 de goto de 2023\n",
    "\n",
    "\n",
    "# tokenizer = Tokenizer(num_words=3000)\n",
    "# tokenizer.fit_on_texts(X_train)\n",
    "\n",
    "# X_train = tokenizer.texts_to_sequences(X_train)\n",
    "# X_test = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "# maxlen = 200\n",
    "\n",
    "# X_train = pad_sequences(X_train, padding='post', maxlen=maxlen)\n",
    "# X_test = pad_sequences(X_test, padding='post', maxlen=maxlen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "DJKa4uVrWLA9"
   },
   "outputs": [],
   "source": [
    "from numpy import array\n",
    "from numpy import asarray\n",
    "from numpy import zeros\n",
    "\n",
    "\n",
    "embeddings_dictionary = dict()\n",
    "\n",
    "glove_file = open(\"../Datasets/glove.6B.100d.txt\", encoding=\"utf-8\")\n",
    "# open(\"glove.6B.50d.txt\", 'r', encoding=\"utf-8\") como f:\n",
    "\n",
    "for line in glove_file:\n",
    "    records = line.split()\n",
    "    word = records[0]\n",
    "    vector_dimensions = asarray(records[1:], dtype='float32')\n",
    "    embeddings_dictionary[word] = vector_dimensions\n",
    "glove_file.close()\n",
    "\n",
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, index in tokenizer.word_index.items():\n",
    "    embedding_vector = embeddings_dictionary.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[index] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6ziJEBbfDIR4"
   },
   "source": [
    "# **BI-GRU 64**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing import text, sequence\n",
    "from tensorflow.keras import initializers, regularizers, constraints, optimizers, layers\n",
    "from tensorflow.keras import Model, Input, Sequential\n",
    "from tensorflow.keras.layers import Dense, Input, LSTM, SimpleRNN, Embedding, Dropout, SpatialDropout1D, Activation, Conv1D,GRU\n",
    "from tensorflow.keras.layers import Conv1D, Bidirectional, GlobalMaxPool1D, MaxPooling1D, BatchNormalization, Add, Flatten\n",
    "from tensorflow.keras.layers import GlobalMaxPooling1D, GlobalAveragePooling1D, concatenate, SpatialDropout1D\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173245"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import tensorflow as tf\n",
    "deep_inputs = Input(shape=(maxlen,))\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False)(deep_inputs)\n",
    "model = SpatialDropout1D(0.2)(embedding_layer)\n",
    "model = Bidirectional(GRU(64,return_sequences=True,dropout=0.1,recurrent_dropout=0.1 ))(model)\n",
    "model = Conv1D(64, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(model)\n",
    "avg_pool = GlobalAveragePooling1D()(model)\n",
    "max_pool = GlobalMaxPooling1D()(model)\n",
    "model = concatenate([avg_pool, max_pool])\n",
    "dense_layer1 = Dense(2, activation=\"sigmoid\")(model)\n",
    "Bi_GRU_glove = Model(deep_inputs, dense_layer1)\n",
    "Bi_GRU_glove.compile(loss='binary_crossentropy',optimizer='adam',metrics=[tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9513568868407578\n",
      "0.9549180327868853\n",
      "0.9779713114754098\n",
      "0.9815573770491803\n",
      "0.983094262295082\n",
      "Mean Accuracy over KFold = 5: 0.969779574089463\n"
     ]
    }
   ],
   "source": [
    "# Crear una instancia de kfolds con n=5\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Lista para almacenar los resultados de precisión\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    Bi_GRU_glove.fit(X_train, y_train, epochs=10, batch_size=64, verbose=0)\n",
    "    y_pred = np.argmax(Bi_GRU_glove.predict(X_test), axis=-1)\n",
    "    accuracy = accuracy_score(np.argmax(y_test, axis=-1), y_pred)\n",
    "#     print()\n",
    "    print(accuracy)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "\n",
    "# Calcular la precisión media en todos los folds\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "print('Mean Accuracy over KFold = 5:', mean_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "import tensorflow as tf\n",
    "deep_inputs = Input(shape=(maxlen,))\n",
    "embedding_layer = Embedding(vocab_size, 100, weights=[embedding_matrix], trainable=False)(deep_inputs)\n",
    "model = SpatialDropout1D(0.2)(embedding_layer)\n",
    "model = Bidirectional(GRU(64,return_sequences=True,dropout=0.1,recurrent_dropout=0.1 ))(model)\n",
    "model = Conv1D(64, kernel_size = 3, padding = \"valid\", kernel_initializer = \"glorot_uniform\")(model)\n",
    "avg_pool = GlobalAveragePooling1D()(model)\n",
    "max_pool = GlobalMaxPooling1D()(model)\n",
    "model = concatenate([avg_pool, max_pool])\n",
    "dense_layer1 = Dense(2, activation=\"sigmoid\")(model)\n",
    "Bi_GRU_glove = Model(deep_inputs, dense_layer1)\n",
    "Bi_GRU_glove.compile(loss='binary_crossentropy',optimizer='adam',metrics=[tf.keras.metrics.AUC()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear una instancia de kfolds con n=5\n",
    "kf = KFold(n_splits=5, shuffle=True)\n",
    "\n",
    "# Lista para almacenar los resultados de precisión\n",
    "accuracy_scores = []\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    Bi_GRU_glove.fit(X_train, y_train, epochs=10, batch_size=64, verbose=0)\n",
    "    y_pred = np.argmax(Bi_GRU_glove.predict(X_test), axis=-1)\n",
    "    accuracy = accuracy_score(np.argmax(y_test, axis=-1), y_pred)\n",
    "#     print()\n",
    "    print(accuracy)\n",
    "    accuracy_scores.append(accuracy)\n",
    "    \n",
    "\n",
    "# Calcular la precisión media en todos los folds\n",
    "mean_accuracy = np.mean(accuracy_scores)\n",
    "print('Mean Accuracy over KFold = 5:', mean_accuracy)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "LSTM_Bi-LSTM_GRU_Bi-GRU.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
